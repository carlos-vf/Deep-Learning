%\documentclass[serif, aspectratio=169]{beamer}  % for 16:9 ratio
\documentclass[serif]{beamer}  % for 4:3 ratio
\usepackage[T1]{fontenc} 
\usepackage{hyperref}
\usepackage{latexsym,amsmath,xcolor,multicol,booktabs,calligra}
\usepackage{graphicx,pstricks,listings,stackengine}
\usepackage{multimedia}

\author{
    Valeria De Stasio \\ 
    \and  
    Christian Faccio \\
    \and  
    Carlos Velázquez Fernández
}
\title{Detection and tracking of fishes: \\ an analysis of the YOLOv8 model}
\date{\small July 25, 2025}
\usepackage{UoWstyle}

% defs
\def\cmd#1{\texttt{\color{red}\footnotesize $\backslash$#1}}
\def\env#1{\texttt{\color{blue}\footnotesize #1}}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{RGB}{153,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\definecolor{halfgray}{gray}{0.55}

\lstset{
    basicstyle=\ttfamily\tiny,
    keywordstyle=\bfseries\color{deepblue},
    emphstyle=\ttfamily\color{deepred},    % Custom highlighting style
    stringstyle=\color{deepgreen},
    numbers=left,
    numberstyle=\tiny\color{halfgray},
    rulesepcolor=\color{red!20!green!20!blue!20},
    frame=shadowbox,
}


\begin{document}

\begin{frame}
    \vfill
    \begin{center}
        \includegraphics[keepaspectratio, scale=0.15]{images/logo.jpg}
        
        \vspace{1cm}
        
        \begin{beamercolorbox}[wd=\textwidth,center,rounded=true]{title}
            {\textbf{Detection, classification and tracking of fishes: \\ an analysis of the YOLOv8 model}}
        \end{beamercolorbox}
        
        \vspace{1cm}
        
        {July 25, 2025}
    \end{center}
    \vfill
\end{frame}

\begin{frame}    
\tableofcontents[sectionstyle=show,
subsectionstyle=show/shaded/hide,
subsubsectionstyle=show/shaded/hide]
\end{frame}

\section{Theory}

\begin{frame}
\frametitle{Fish detection problem}
\end{frame}

\begin{frame}
\frametitle{History of fish detection}
\end{frame}

\begin{frame}
\frametitle{YOLO}
\end{frame}

\begin{frame}
\frametitle{YOLOv8}
\end{frame}

\begin{frame}
\frametitle{Sub-things to explain}
\end{frame}

\section{Detection}

\begin{frame}
\frametitle{Datasets}
\begin{columns}
\begin{column}{0.5\textwidth}
	\centering
	\textbf{DeepFish  --> }\\
\end{column}

\begin{column}{0.5\textwidth}
	\centering
	\includegraphics[width=0.95\textwidth]{images/deepfish.png}
\end{column}
\end{columns}

\vspace{1cm}

\begin{columns}
\begin{column}{0.5\textwidth}
	\centering
	\includegraphics[width=0.95\textwidth]{images/f4k.png}	
\end{column}

\begin{column}{0.5\textwidth}
	\centering
	\textbf{<--  Fish4Knowledge}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]
\frametitle{Datasets structure}
\begin{columns}
\begin{column}{0.3\textwidth}
\centering
\textbf{DeepFish}
\begin{lstlisting}[language=python]
.
├── 7117
│   ├── train
│   └── valid
├── 7268
├── 7393
├── 7398
├── 7426
├── 7434
├── 7463
├── 7482
├── 7490
├── 7585
├── 7623
├── 9852
├── 9862
├── 9866
├── 9870
├── 9892
├── 9894
├── 9898
├── 9907
├── 9908
├── classes.txt
├── Nagative_samples
└── test
\end{lstlisting}
\end{column}

\begin{column}{0.3\textwidth}
\centering
\textbf{Fish4Knowledge}
\begin{lstlisting}[language=python]
    f4k
    ┣ fish_image
    ┃ ┣ fish_01
    ┃ ┃ ┣ fish_x.png
    ┃ ┃ ┗ ...
    ┣ gt_bounding_boxes
    ┃ ┣ gt_106.xml
    ┃ ┗ ...
    ┣ mask_image
    ┃ ┣ mask_01
    ┃ ┃ ┣ mask_x.png
    ┃ ┃ ┗ ...
    ┗ videos
      ┣ gt_106.mp4
      ┗ ...

\end{lstlisting}
\end{column}

\begin{column}{0.3\textwidth}
\centering
\textbf{YOLO format}
\begin{lstlisting}[language=python]
.
├── data.yaml
├── test
│   ├── images
│   ├── labels
│   └── labels.cache
├── train
│   ├── images
│   ├── labels
│   └── labels.cache
└── val
    ├── images
    ├── labels
    └── labels.cache
\end{lstlisting}
\end{column}
\end{columns}
\end{frame}

\begin{frame}[fragile]
\frametitle{Configuration files (data.yaml)}
\begin{columns}
\begin{column}{0.45\textwidth}
\begin{lstlisting}[language=python]
train: path_to_train/images
val: path_to_val/images
test: path_to_test/images

nc: 1
names: ['Fish']
\end{lstlisting}
\end{column}

\begin{column}{0.45\textwidth}
\begin{lstlisting}[language=python]
train: path_to_train/images
val: path_to_val/images
test: path_to_test/images

nc: 23
names: [
  'Caranx_sexfasciatus',
  'F1', 
  'F2',
  'F3', 
  'F4',
  'F5',
  'F6',
  'F7',
  'Acanthopagrus_palmaris',
  'Lutjanus_russellii',
  'acanthopagrus_and_caranx',
  'acanthopagrus_palmaris', 
  'Gerres',
  'Caranx',
  'Amniataba_caudivittatus',
  'gerres_2',
  'gerres',
  'Epinephelus',
  'Fish',
  'juvenile',
  'palmaris',
  'EJP',
  'caudivittatus'
]
\end{lstlisting}
\end{column}
\end{columns}
\end{frame}

\begin{frame}
\frametitle{YOLOv8 models}
\begin{center}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Model} & \textbf{size} & \textbf{mAP$^{\text{val}}$} & \textbf{Speed} & \textbf{Speed} & \textbf{params} & \textbf{FLOPs} \\
 & \textbf{(pixels)} & \textbf{50-95} & \textbf{CPU ONNX} & \textbf{A100 TensorRT} & \textbf{(M)} & \textbf{(B)} \\
 &  &  & \textbf{(ms)} & \textbf{(ms)} &  &  \\
\hline
YOLOv8n & 640 & 37.3 & 80.4 & 0.99 & 3.2 & 8.7 \\
\hline
YOLOv8s & 640 & 44.9 & 128.4 & 1.20 & 11.2 & 28.6 \\
\hline
YOLOv8m & 640 & 50.2 & 234.7 & 1.83 & 25.9 & 78.9 \\
\hline
YOLOv8l & 640 & 52.9 & 375.2 & 2.39 & 43.7 & 165.2 \\
\hline
YOLOv8x & 640 & 53.9 & 479.1 & 3.53 & 68.2 & 257.8 \\
\hline
\end{tabular}%
}
\end{center}
\end{frame}

\begin{frame}
\frametitle{AdamW}
$$
\phi_{t+1} \leftarrow \phi_t - \alpha \cdot (\frac{m_t}{v_t + \epsilon} + \lambda \phi_t)
$$
\vspace{0.5cm}
Where:
\begin{itemize}
	\item $m_t \leftarrow \frac{\beta_1 \cdot m_{t-1} + (1-\beta_1)g_t}{1 - \beta_1^t}$
	\item $v_t \leftarrow \frac{\beta_2 \cdot v_{t-1} + (1-\beta_2)g_t^2}{1 - \beta_2^t}$
	\item $g_t \leftarrow \nabla L_t(\phi_{t-1}) \quad  \mathbf{ (no  }\lambda \phi_{t-1} \mathbf{  here!)}$
\end{itemize}
\end{frame}

\begin{frame}
\centering
\includegraphics[width=\textwidth]{images/adamw_algo.png}
\footnote{\cite{loshchilov2019decoupledweightdecayregularization}}
\end{frame}

\begin{frame}
\centering
\includegraphics[width=0.8\textwidth]{images/adamw_com.png}
\footnote{\cite{loshchilov2019decoupledweightdecayregularization}}
\end{frame}

\begin{frame}
\frametitle{Loss Function}
$$
loss = L_{cls} + L_{box} + L_{DFL}
$$
\begin{itemize}
	\item \textbf{Classification loss:} crucial for predicting the correct class of objects.
	\item \textbf{Box loss:} ensures that the bounding boxes around objects are accurate.
	\item \textbf{DFL:} Distributed Focal Loss, boosts performance by distributing the loss function across different object scales and classes.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{General Parameters}
\begin{center}
\small
\begin{tabular}{|l|c|p{5.5cm}|}
\hline
\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\
\hline
Epochs & 50-100 & Number of training iterations \\
\hline
Batch Size & 16 & Images processed simultaneously \\
\hline
Image Size & 640 & Input image resolution (pixels) \\
\hline
Optimizer & AdamW & Adaptive moment estimation with weight decay \\
\hline
Learning Rate & 0.001 & Initial learning rate with cosine scheduling \\
\hline
Weight Decay & 0.0005 & L2 regularization strength \\
\hline
patience & 10 & Epochs to wait before early stopping \\
\hline
Warmup epochs & 3 & Gradual learning rate increase at start \\
\hline
cos\_lr & True & Cosine learning rate scheduler \\
\hline
close\_mosaic & 10 & Disable mosaic augmentation in last N epochs \\
\hline
\end{tabular}
\end{center}
\end{frame}


\begin{frame}
\frametitle{Specific Parameters (single-class vs multi-class)}
\begin{center}
\small
\begin{tabular}{|l|c|c|p{4cm}|}
\hline
	\textbf{Parameter} & \textbf{Single-class} & \textbf{Multi-class} & \textbf{Description} \\
\hline
cls & 0.5 & 1.0 & Weight affecting importance of correct class prediction\\
\hline
box & 7.5 & 7.5 & Weight influencing emphasis on accurately predicting bounding box coordinates\\
\hline
dfl & 1.5 & 1.5 & Weight used for fine-grained classification\\
\hline
mixup & 0.0 & 0.15 & Blends two images and their labels, creating composite image\\
\hline
copy\_paste & 0.0 & 0.3 & Copies and pastes objects across images to increase object instances\\
\hline
\end{tabular}
\end{center}
\end{frame}

\begin{frame}
\frametitle{Training}
\centering
\includegraphics[width=0.7\textwidth]{images/training1.png}
\vspace{0.5cm}
\includegraphics[width=0.7\textwidth]{images/training2.png}
\end{frame}

\begin{frame}
\centering
\textbf{Mixup feature}
\begin{columns}
\begin{column}{0.5\textwidth}
	\centering
	\includegraphics[width=0.8\textwidth]{images/mixup_1.jpg}
\end{column}

\begin{column}{0.5\textwidth}
	\centering
	\includegraphics[width=0.8\textwidth]{images/mixup_2.jpg}
\end{column}
\end{columns}

\vspace{0.3cm}

\begin{columns}
\begin{column}{0.5\textwidth}
	\centering
	\textbf{Mosaic feature}
	\includegraphics[width=0.8\textwidth]{images/mosaic.jpg}	
\end{column}

\begin{column}{0.5\textwidth}
	\centering
	\textbf{Cutout feature}
	\includegraphics[width=0.8\textwidth]{images/cutout.jpg}
\end{column}
\end{columns}

\end{frame}

\begin{frame}
\frametitle{NMS}
The \textbf{Non-Maximum Suppression} is a technique that cleans up the output of a detection model by filtering out redundant and overlapping bounding boxes to ensure that each object is identified only once. It operates by iterating through the predicted bounding boxes and making decisions based on two key metrics: \textbf{confidence scores} and the \textbf{IoU} threshold:
\begin{enumerate}
	\item Sort by confidence 
	\item Select the best box
	\item Repeat
\end{enumerate}
(IoU means Intersection over Union and the higher it is for a box, the more it overlaps the others)
\end{frame}

\begin{frame}
\frametitle{Inference}
\centering
\begin{columns}
\begin{column}{0.5\textwidth}
	\centering
	\includegraphics[width=\textwidth]{images/9894_Amniataba_caudivittatus_f000002.jpg}
\end{column}

\begin{column}{0.5\textwidth}
	\centering
	\includegraphics[width=\textwidth]{images/9866_acanthopagrus_and_caranx_f000041.jpg}
\end{column}
\end{columns}

\begin{columns}
\begin{column}{0.5\textwidth}
	\centering
	\includegraphics[width=\textwidth]{images/7268_F1_f000242.jpg}	
\end{column}

\begin{column}{0.5\textwidth}
	\centering
	\includegraphics[width=\textwidth]{images/9908_Acanthopagrus_palmaris_f000010.jpg}
\end{column}
\end{columns}


\end{frame}

\section{Tracking}

\begin{frame}
    \frametitle{The Tracking Challenge: Occlusion \& ID Switches}
    
    \textbf{Problem:} In complex underwater scenes, fish are frequently occluded by objects or other fish.
    \vspace{1em}
            
    A naive tracker will often:
    \begin{itemize}
        \item \textbf{Lose the track} entirely when the fish disappears.
        \item \textbf{Create a new ID} when the fish reappears (\textcolor{deepred}{ID Switch}).
    \end{itemize}
    
    \vspace{1em}
    \textbf{Goal:} Maintain a persistent, correct ID for each fish despite occlusions.
\end{frame}

\begin{frame}
    \frametitle{The ByteTrack Algorithm}
    
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{Stage 1: High-Confidence Match}
            \begin{itemize}
                \item Uses motion prediction (Kalman Filter) to estimate the next position of existing tracks.
                \item Matches these predictions with high-confidence detections from the YOLO model.
            \end{itemize}
        \end{column}
        
        \begin{column}{0.5\textwidth}
            \textbf{Stage 2: Low-Confidence Match}
            \begin{itemize}
                \item Instead of discarding low-confidence detections, it keeps them.
                \item It attempts to match these "doubtful" detections to the tracks that were lost in Stage 1.
            \end{itemize}
        \end{column}
    \end{columns}
    
\end{frame}

\begin{frame}
    \frametitle{Occlusion Example}
    
    \begin{columns}[T,totalwidth=\textwidth] 
        \begin{column}{0.32\textwidth}
            \centering
            \includegraphics[width=\linewidth]{images/occlusion_1.png}
            \vspace{0.5em}
            \tiny
            \textbf{1. Before Occlusion} \\
            The fish ID 43 is clearly visible and being tracked.
        \end{column}
        
        \begin{column}{0.32\textwidth}
            \centering
            \includegraphics[width=\linewidth]{images/occlusion_2.png}
            \vspace{0.5em}
            \tiny
            \textbf{2. During Occlusion} \\
            Fish ID 43 is now hidden behind an object.
        \end{column}
        
        \begin{column}{0.32\textwidth}
            \centering
            \includegraphics[width=\linewidth]{images/occlusion_3.png}
            \vspace{0.5em}
            \tiny
            \textbf{3. After Occlusion} \\
            The fish reappears. ByteTrack re-identifies it as ID 43.
        \end{column}
    \end{columns}
\end{frame}


\section{Results}

\section{Conclusions}

\bibliography{ref}
\bibliographystyle{plain}

\end{document}
