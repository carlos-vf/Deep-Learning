# Deep-Learning


## Sources
- Hand gesture recognition:
  - [TY-Net](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10353968&tag=1)
  - [Real-Time Hand Gesture Recognition](https://www.mdpi.com/2076-3417/11/9/4164)
- Coral detection:
  - [Project](https://universe.roboflow.com/capstone-akjww/coral-reef-health-identifier)
  - [MFFN YOLO](https://www.researchgate.net/publication/367317996_MAFFN_YOLOv5_Multi-Scale_Attention_Feature_Fusion_Network_on_the_YOLOv5_Model_for_the_Health_Detection_of_Coral-Reefs_Using_a_Built-In_Benchmark_Dataset)
    - [Connected papers](https://www.connectedpapers.com/main/ae009d5d335e9b6bc4023ff2a616fd6ed59c5dfc/Maffn_Yolov5%3A-Multi%20Scale-Attention-Feature-Fusion-Network-on-Yolov5-Model-for-the-Health-Detection-of-Coral%20Reefs-Using-Built%20In-Benchmark-Dataset/graph)
- Fish detection:
  - [FishNet](https://openaccess.thecvf.com/content/ICCV2023/papers/Khan_FishNet_A_Large-scale_Dataset_and_Benchmark_for_Fish_Recognition_Detection_ICCV_2023_paper.pdf)
    - [Connected papers](https://www.connectedpapers.com/main/ceabdbedda22134952b7695936822e202b50320a/FishNet%3A-A-Large%20scale-Dataset-and-Benchmark-for-Fish-Recognition%2C-Detection%2C-and-Functional-Trait-Prediction/graph)
  - [YOLO-Fish](https://www.sciencedirect.com/science/article/pii/S1574954122002977?ref=pdf_download&fr=RR-9&rr=9554add4aac3ea35)
  - [WildFish Dataset](https://github.com/PeiqinZhuang/WildFish?tab=readme-ov-file)
- [YOLO versions](https://viso.ai/computer-vision/yolo-explained/)


## Roadmap

1. Create the full implementation, does not matter what we use but it has to work -> this demonstrates that we are capable of using modern computer vision concepts and tools
2. Look at the inefficiencies and try to solve them on our own (not all, it is enough one since they are difficult to solve) -> this is what we bring in this project
3. Integrate everything in video
4. Comparison with other models and performance analysis
5. Create a stunning presentation
